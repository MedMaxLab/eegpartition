{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28040bc3-9f29-44d6-99d0-4d891caf0c76",
   "metadata": {},
   "source": [
    "# Notebook for Result Visualization\n",
    "\n",
    "This notebook is used to generate all the figures that summarize \\\n",
    "the results of the data\n",
    "partition analysis. It is divided in three main subsections:\n",
    "\n",
    "1. Intra-subject vs Inter-subject variability\n",
    "2. LNSO vs N-LNSO\n",
    "3. LOSO vs Full N-LOSO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf08b48d-d843-4d2c-8bd9-97fd1c6bce21",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a299d-d612-4994-b5fd-702156d2c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import math\n",
    "from AllFnc.utilities import (\n",
    "    GetLearningRateString,\n",
    "    get_full_name,\n",
    "    gather_metric_values,\n",
    "    convert_performance_totable\n",
    ")\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "\n",
    "letters= [\"A\", \"B\", \"C\", \"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bce650-635e-4c55-b2eb-c0385bd76708",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"light\"\n",
    "\n",
    "custom_params_dark = {\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.labelcolor': '.15',\n",
    "    'xtick.direction': 'out',\n",
    "    'ytick.direction': 'out',\n",
    "    'xtick.color': '.15',\n",
    "    'ytick.color': '.15',\n",
    "    'axes.axisbelow': True,\n",
    "    'grid.linestyle': '-',\n",
    "    'text.color': '.15',\n",
    "    'font.family': ['sans-serif'],\n",
    "    'font.sans-serif': [\n",
    "        'Arial',\n",
    "        'DejaVu Sans',\n",
    "        'Liberation Sans',\n",
    "        'Bitstream Vera Sans',\n",
    "        'sans-serif'\n",
    "    ],\n",
    "    'lines.solid_capstyle': 'round',\n",
    "    'patch.edgecolor': 'w',\n",
    "    'patch.force_edgecolor': True,\n",
    "    'image.cmap': 'rocket',\n",
    "    'xtick.top': False,\n",
    "    'ytick.right': False,\n",
    "    'axes.grid': True,\n",
    "    'axes.facecolor': '#EAEAF2',\n",
    "    'axes.edgecolor': '#0072b2',\n",
    "    'grid.color': 'white',\n",
    "    'axes.spines.left': True,\n",
    "    'axes.spines.bottom': True,\n",
    "    'axes.spines.right': True,\n",
    "    'axes.spines.top': True,\n",
    "    'xtick.bottom': False,\n",
    "    'ytick.left': False\n",
    "}\n",
    "custom_params_light = {\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.top\": False,\n",
    "    'axes.grid': True,\n",
    "    'grid.linestyle': '-',\n",
    "    'grid.color': 'lightgray',\n",
    "}\n",
    "if style == \"dark\":\n",
    "    folder = \"DarkTheme\"\n",
    "    sns.set_style(\"darkgrid\", rc = custom_params_dark)\n",
    "elif style == \"light\":\n",
    "    folder = \"LightTheme\"\n",
    "    sns.set_theme(style=\"ticks\", rc=custom_params_light)\n",
    "sns.set_context(\"paper\", font_scale=1.5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c3c6b-43aa-4d21-a1ab-9a9ac4d61438",
   "metadata": {},
   "source": [
    "## Intra-subject (KFOLD) vs Inter-subject (LNSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4fdb31-b027-4d2b-9a10-e64d98489408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = 'accuracy_weighted'\n",
    "task = ['pds', 'alz', 'bci']\n",
    "model = ['shn', 'egn', 'dcn', 'res']\n",
    "partition = ['KFOLD', 'LNSO']\n",
    "performances    = gather_metric_values(metric, task, model, partition)\n",
    "performances_df = convert_performance_totable(performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36938b38-87cd-44d8-aca8-c994ff5d9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = 25\n",
    "letters= [\"A\", \"B\", \"C\", \"D\"]\n",
    "fig, ax = plt.subplots(2, 2, figsize=(19.72, 15.5))\n",
    "for n, i in enumerate(model):\n",
    "    row, col = n//2, n%2\n",
    "    model_df = performances_df.loc[performances_df[\"Model\"]==i]\n",
    "    model_df.loc[:,\"Task\"] = model_df.loc[:,\"Task\"].apply(get_full_name)\n",
    "    sns.stripplot(\n",
    "        x         = 'Task',\n",
    "        y         = 'Metric',\n",
    "        data      = model_df,\n",
    "        legend    = False,\n",
    "        linewidth = 1,\n",
    "        hue       = 'Partition',\n",
    "        dodge     = True,\n",
    "        ax        = ax[row, col],\n",
    "        size      = 12,\n",
    "        palette   = [\"#56b4e9\", \"#e69f00\"],\n",
    "        alpha    = 0.9\n",
    "    )\n",
    "    ax[row, col].set_yticks([i*10 for i in range(2, 11)])\n",
    "    ax[row, col].set_title( f'Model: {get_full_name(i)}',fontsize = font+3, pad=16)\n",
    "    if row==1:\n",
    "        ax[row, col].set_xlabel('Task', fontsize = font, labelpad=12)\n",
    "    else:\n",
    "        ax[row,col].xaxis.label.set_visible(False)\n",
    "    if col==0:\n",
    "        ax[row, col].set_ylabel('Balanced Accuracy %', fontsize = font)\n",
    "    else:\n",
    "        ax[row,col].yaxis.label.set_visible(False)\n",
    "    ax[row, col].set_ylim(5*5,103)\n",
    "    ax[row, col].tick_params(axis='both', which='major', labelsize=font-5)\n",
    "    ax[row, col].text(2.2,93,f'$({letters[n]})$',fontsize = font+6)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax[row, col].spines[axis].set_linewidth(1.5)\n",
    "    ax[row, col].legend([\"Sample-based K-Fold\", \"Leave-N-Subjects-Out\"], fontsize = font - 7.5, loc = \"lower left\")\n",
    "\n",
    "fig.suptitle( f'Sample-based K-Fold vs. Leave-N-Subjects-Out',fontsize = font+8)\n",
    "plt.subplots_adjust(top=0.9, hspace=0.25, wspace=0.25)\n",
    "plt.savefig(f\"Images/{folder}/Kfold_vs_LNSO_concat_vertical.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9de7e8-cc10-4f39-a59e-60cdce5ec6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = 22\n",
    "for n, i in enumerate(model):\n",
    "    model_df = performances_df.loc[performances_df[\"Model\"]==i]\n",
    "    model_df.loc[:,\"Task\"] = model_df.loc[:,\"Task\"].apply(get_full_name)\n",
    "    #fig, ax = plt.subplots(figsize=(12, 11))\n",
    "    fig, ax = plt.subplots(figsize=(8, 7.2))\n",
    "    #sns.boxplot(x='Task', y='Metric', hue='Partition', data=model_df, showfliers=False, ax=ax)\n",
    "    sns.stripplot(\n",
    "        x         = 'Task',\n",
    "        y         = 'Metric',\n",
    "        data      = model_df,\n",
    "        legend    = False,\n",
    "        linewidth = 1,\n",
    "        hue       = 'Partition',\n",
    "        dodge     = True,\n",
    "        ax        = ax,\n",
    "        size      = 9,\n",
    "        palette   = [\"#56b4e9\", \"#e69f00\"],\n",
    "        alpha    = 0.9\n",
    "    )\n",
    "    #ax.set_yticks([i*5 for i in range(5, 21)])\n",
    "    ax.set_yticks([i*10 for i in range(2, 11)])\n",
    "    #ax.set_title( f'Sample-based K-Fold vs LNSO\\nModel: {get_full_name(i)}',fontsize = font+3)\n",
    "    ax.set_title( f'Model: {get_full_name(i)}',fontsize = font+3, pad=12)\n",
    "    ax.set_xlabel('Task', fontsize = font, labelpad=12)\n",
    "    ax.set_ylabel('Balanced Accuracy %', fontsize = font)\n",
    "    ax.set_ylim(5*5,103)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=font-5)\n",
    "    ax.text(2.2,93,f'$({letters[n]})$',fontsize = font+6)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(1.5)\n",
    "    plt.legend([\"Sample-based K-Fold\", \"Leave-N-Subjects-Out\"], fontsize = font - 6.1, loc = \"lower left\")\n",
    "    plt.savefig(f\"Images/{folder}/Kfold_vs_LNSO_model_{get_full_name(i)}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b004c45-5481-4fc6-ba53-4eba8cb7a3e9",
   "metadata": {},
   "source": [
    "## Quantitative analysis using additional nested level\n",
    "\n",
    "Comparing the results of subject-based and sample-based cross-validation methods\n",
    "is not possible. Groups have folds that are not completely independent\n",
    "(there is a 10% overlap), nor they can be considered paired. Both the Wilcoxon signed-rank \n",
    "or the Mann Whiteny U cannot be used in this context. Additionally, any statistical test\n",
    "will tell if a mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05961625-175d-4ef8-9441-6f33224646be",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'accuracy_weighted'\n",
    "task = ['pds', 'alz', 'bci']\n",
    "model = ['shn', 'egn', 'dcn', 'res']\n",
    "partition = ['NKFOLD','NLNSO']\n",
    "\n",
    "performances, performances_val = gather_metric_values(metric, task, model, partition, True)\n",
    "performances_df = convert_performance_totable(performances, performances_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e937d-6d7b-4140-9848-f31d9a653aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = performances_df.groupby([\"Partition\", \"Task\", \"Model\", \"Outer\"])\n",
    "#df2 = grouped.apply(lambda x: x.Metric[x.MetricVal.idxmax()], include_groups=False)\n",
    "df2 = grouped.apply(lambda x: x.Metric.mean(), include_groups=False)\n",
    "df2 = df2.reset_index().rename(columns={0: \"Metric\"})\n",
    "df3 = grouped.apply(lambda x: x.MetricVal.mean(), include_groups=False)\n",
    "df3 = df3.reset_index().rename(columns={0: \"Metric\"})\n",
    "df2[\"MetricDiff\"] = df3[\"Metric\"]- df2[\"Metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b309f-2388-4fa0-8693-5ff6e86609e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = 25\n",
    "letters= [\"A\", \"B\", \"C\", \"D\"]\n",
    "fig, ax = plt.subplots(2, 2, figsize=(19.72, 15.5))\n",
    "for n, i in enumerate(model):\n",
    "    row, col = n//2, n%2\n",
    "    model_df = df2.loc[df2[\"Model\"]==i]\n",
    "    model_df.loc[:,\"Task\"] = model_df.loc[:,\"Task\"].apply(get_full_name)\n",
    "    sns.stripplot(\n",
    "        x         = 'Task',\n",
    "        y         = 'MetricDiff',\n",
    "        data      = model_df,\n",
    "        legend    = False,\n",
    "        linewidth = 1,\n",
    "        hue       = 'Partition',\n",
    "        dodge     = True,\n",
    "        ax        = ax[row, col],\n",
    "        size      = 12,\n",
    "        palette   = [\"#56b4e9\", \"#e69f00\"],\n",
    "        alpha    = 0.9\n",
    "    )\n",
    "    ax[row, col].set_yticks([i*10 for i in range(-6, 11)])\n",
    "    ax[row, col].set_title( f'Model: {get_full_name(i)}',fontsize = font+3, pad=16)\n",
    "    if row==1:\n",
    "        ax[row, col].set_xlabel('Task', fontsize = font, labelpad=12)\n",
    "    else:\n",
    "        ax[row,col].xaxis.label.set_visible(False)\n",
    "    if col==0:\n",
    "        ax[row, col].set_ylabel('Bias Accuracy Balanced', fontsize = font)\n",
    "    else:\n",
    "        ax[row,col].yaxis.label.set_visible(False)\n",
    "    ax[row, col].set_ylim(-30,80)\n",
    "    ax[row, col].tick_params(axis='both', which='major', labelsize=font-5)\n",
    "    ax[row, col].text(2.2,72,f'$({letters[n]})$',fontsize = font+6)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax[row, col].spines[axis].set_linewidth(1.5)\n",
    "    ax[row, col].legend([\"Sample-based K-Fold\", \"Leave-N-Subjects-Out\"], fontsize = font - 7.5, loc = \"lower right\")\n",
    "\n",
    "fig.suptitle( f'Accuracy Estimation Bias - Sample-based K-Fold vs LNSO',fontsize = font+8)\n",
    "plt.subplots_adjust(top=0.9, hspace=0.25, wspace=0.25)\n",
    "plt.savefig(f\"Images/{folder}/Bias_Kfold_vs_LNSO_concat.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e0635-85eb-4658-ba9e-4280f6b29b71",
   "metadata": {},
   "source": [
    "## LNSO vs N-LNSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e42a54-6800-432c-a7f2-bb7371f8951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'accuracy_weighted'\n",
    "task = ['pds', 'alz', 'bci']\n",
    "model = ['shn', 'egn', 'dcn', 'res']\n",
    "partition = ['LNSO', 'NLNSO']\n",
    "\n",
    "performances, performancesval = gather_metric_values(metric, task, model, partition, True)\n",
    "performances_df = convert_performance_totable(performances)\n",
    "performancesval_df = convert_performance_totable(performancesval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6deddcd-95b4-4b04-ab74-d2988ac2b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performances_df[\"Task \"] = performances_df[\"Task\"].apply(\n",
    "    lambda x: {'pds': 'Parkinson', 'alz':'Alzheimer', 'bci':'BCI'}.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd43ae5-e21c-46d5-bbe8-016366866a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in enumerate(model):\n",
    "    nlnso_pd_tot = []\n",
    "    lnso_tot = []\n",
    "    for k in task:\n",
    "        lnso = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"LNSO\")\n",
    "        ), \"Metric\"].values\n",
    "        lnso_tot += lnso.tolist()\n",
    "        nlnso_pd = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"NLNSO\")\n",
    "        )]\n",
    "        nlnso_pd.loc[:,'Outer'] = lnso[nlnso_pd['Outer'].values-1]\n",
    "        if not(isinstance(nlnso_pd_tot, pd.DataFrame)):\n",
    "            nlnso_pd_tot = nlnso_pd\n",
    "        else:\n",
    "            try:\n",
    "                nlnso_pd_tot = pd.concat([nlnso_pd_tot, nlnso_pd])\n",
    "            except:\n",
    "                nlnso_pd_tot = nlnso_pd\n",
    "    lnso_tot = np.array(lnso_tot)\n",
    "    nlnso = nlnso_pd_tot[\"Metric\"].values\n",
    "    nlnso = nlnso.reshape(-1,10)\n",
    "    nlnso_med = np.median(nlnso,1)\n",
    "    nlnso_min = np.min(nlnso,1)\n",
    "    nlnso_max = np.max(nlnso,1)\n",
    "    nlnso_25 = np.percentile(nlnso,25, 1)\n",
    "    nlnso_75 = np.percentile(nlnso,75, 1)\n",
    "    nlnso_err = np.stack((nlnso_med-nlnso_min, nlnso_max-nlnso_med),1).T\n",
    "    nlnso_err = np.stack((nlnso_med-nlnso_25, nlnso_75-nlnso_med),1).T\n",
    "    nlnso_iqr = np.subtract(*np.percentile(nlnso, [75, 25], 1))\n",
    "    font = 22\n",
    "\n",
    "    range_x = np.arange(10)\n",
    "    fig, ax = plt.subplots(figsize=(8, 7.2))\n",
    "    sns.scatterplot(\n",
    "        data=nlnso_pd_tot,\n",
    "        x=\"Outer\",\n",
    "        y=\"Metric\",\n",
    "        hue=\"Task \",\n",
    "        ax=ax,\n",
    "        legend=True,\n",
    "        alpha = 0.8,\n",
    "        palette=[\"#e69f00\", \"#009e73\", \"#f0e442\"],\n",
    "        edgecolors='black',\n",
    "        zorder=2\n",
    "    )\n",
    "    lgnd = ax.legend(fontsize = font-6, loc = \"lower right\", markerscale=2)    \n",
    "    sns.regplot(\n",
    "        data=nlnso_pd_tot, x=\"Outer\", y=\"Metric\",\n",
    "        ax=ax, color='#1f77b4', ci=95,\n",
    "        scatter=False, fit_reg=True,\n",
    "        scatter_kws={'alpha':0.4, 'hue':\"Task\", 'size':15, 'edgecolors':'black'},\n",
    "        line_kws = {'color': \"#0072b2\", 'linewidth': 2}\n",
    "    )\n",
    "    ax.collections[0].set_sizes([50])\n",
    "    ax.plot(np.arange(101), np.arange(101), color= 'black', zorder=1 )\n",
    "    ax.set_yticks([i*10 for i in range(0, 11)])\n",
    "    ax.set_xticks([i*10 for i in range(0, 11)])\n",
    "    ax.set_title(f'Model: {get_full_name(i)}', fontsize = font+3, pad=16)\n",
    "    ax.set_xlabel('LNSO Balanced Accuracy %', fontsize = font)\n",
    "    ax.set_ylabel('N-LNSO Balanced Accuracy %', fontsize = font)\n",
    "    ax.set_ylim(18,102)\n",
    "    ax.set_xlim(18,102)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=font-5)\n",
    "    ax.text(21,93,f'$({letters[n]})$',fontsize = font+6)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(1.5)\n",
    "    file_name = f\"Images/{folder}/LNSO_vs_NLNSO_model_{get_full_name(i)}_all_tasks.pdf\"\n",
    "    plt.savefig(file_name, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b8e90-4583-4db3-8a5c-42fb8641a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = 25\n",
    "fig, ax = plt.subplots(2, 2, figsize=(19.72, 17.7))\n",
    "for n, i in enumerate(model):\n",
    "    row, col = n//2, n%2\n",
    "    nlnso_pd_tot = []\n",
    "    lnso_tot = []\n",
    "    for k in task:\n",
    "        lnso = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"LNSO\")\n",
    "        ), \"Metric\"].values\n",
    "        lnso_tot += lnso.tolist()\n",
    "        nlnso_pd = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"NLNSO\")\n",
    "        )]\n",
    "        nlnso_pd.loc[:,'Outer'] = lnso[nlnso_pd['Outer'].values-1]\n",
    "        if not(isinstance(nlnso_pd_tot, pd.DataFrame)):\n",
    "            nlnso_pd_tot = nlnso_pd\n",
    "        else:\n",
    "            try:\n",
    "                nlnso_pd_tot = pd.concat([nlnso_pd_tot, nlnso_pd])\n",
    "            except:\n",
    "                nlnso_pd_tot = nlnso_pd\n",
    "    lnso_tot = np.array(lnso_tot)\n",
    "    nlnso = nlnso_pd_tot[\"Metric\"].values\n",
    "    nlnso = nlnso.reshape(-1,10)\n",
    "    range_x = np.arange(10)\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=nlnso_pd_tot,\n",
    "        x=\"Outer\",\n",
    "        y=\"Metric\",\n",
    "        hue=\"Task \",\n",
    "        ax=ax[row, col],\n",
    "        legend=True,\n",
    "        alpha = 0.8,\n",
    "        palette=[\"#e69f00\", \"#009e73\", \"#f0e442\"],\n",
    "        edgecolors='black',\n",
    "        zorder=2\n",
    "    )\n",
    "    lgnd = ax[row, col].legend(fontsize = font-7.5, loc = \"lower right\", markerscale=2)\n",
    "\n",
    "    sns.regplot(\n",
    "        data=nlnso_pd_tot, x=\"Outer\", y=\"Metric\",\n",
    "        ax=ax[row, col], color='#1f77b4', ci=95,\n",
    "        scatter=False, fit_reg=True,\n",
    "        scatter_kws={'alpha':0.4, 'hue':\"Task\", 'size':15, 'edgecolors':'black'},\n",
    "        line_kws = {'color': \"#0072b2\", 'linewidth': 2}\n",
    "    )\n",
    "    \n",
    "    ax[row, col].collections[0].set_sizes([90])\n",
    "    ax[row, col].plot(np.arange(101), np.arange(101), zorder = 1, color= \"black\")\n",
    "\n",
    "    if row==1:\n",
    "        ax[row, col].set_xlabel('LNSO Balanced Accuracy %', fontsize = font, labelpad=12)\n",
    "    else:\n",
    "        ax[row,col].xaxis.label.set_visible(False)\n",
    "\n",
    "    if col==0:\n",
    "        ax[row, col].set_ylabel('N-LNSO Balanced Accuracy %', fontsize = font)\n",
    "    else:\n",
    "        ax[row,col].yaxis.label.set_visible(False)\n",
    "\n",
    "    ax[row, col].set_yticks([i*10 for i in range(0, 11)])\n",
    "    ax[row, col].set_xticks([i*10 for i in range(0, 11)])\n",
    "    ax[row, col].set_title(f'Model: {get_full_name(i)}', fontsize = font+3)\n",
    "    ax[row, col].set_ylim(18,102)\n",
    "    ax[row, col].set_xlim(18,102)\n",
    "    ax[row, col].tick_params(axis='both', which='major', labelsize=font-5)\n",
    "    ax[row, col].text(21,93,f'$({letters[n]})$',fontsize = font+6)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax[row, col].spines[axis].set_linewidth(1.5)\n",
    "fig.suptitle(f'Leave-N-Subjects-Out (LNSO) vs. Nested-Leave-N-Subjects-Out (N-LNSO)', fontsize= font+7)\n",
    "plt.subplots_adjust(top=0.9, hspace=0.25, wspace=0.25)\n",
    "plt.savefig(f\"Images/{folder}/LNSO_vs_NLNSO_all_tasks_vertical.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba86ba-6f94-4be3-b9e2-ff7273782a9e",
   "metadata": {},
   "source": [
    "## Quantitative analysis using additional nested level\n",
    "\n",
    "Comparing the results of subject-based and nested-subject-based cross-validation methods\n",
    "is not possible. Groups have folds that are not completely independent, nor they can be considered paired.\n",
    "Both the Wilcoxon signed-rank  or the Mann Whiteny U cannot be used in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e621f6-8316-428d-ad0f-051f033f9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'accuracy_weighted'\n",
    "task = ['pds', 'alz', 'bci']\n",
    "model = ['shn', 'egn', 'dcn', 'res']\n",
    "partition = ['NLNSO', 'NNLNSO']\n",
    "\n",
    "performances, performancesval, performancestest = gather_metric_values(\n",
    "    metric, task, model, partition, True, True\n",
    ")\n",
    "performances_df = convert_performance_totable(performances, performancesval, performancestest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f3a7a-af1e-48e5-88f3-4303fb52534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = (performances_df.loc[performances_df['Partition']=='NLNSO']).copy()\n",
    "df2 = (performances_df.loc[performances_df['Partition']=='NNLNSO']).copy()\n",
    "df2.loc[:,\"MetricValTest\"] = df2.loc[:,\"MetricTest\"] + df2.loc[:,\"MetricVal\"]\n",
    "grouped_nlnso = df1.groupby([\"Partition\", \"Task\", \"Model\", \"Outer\"])\n",
    "grouped_nnlnso = df2.groupby([\"Partition\", \"Task\", \"Model\", \"Repetition\"])\n",
    "\n",
    "df1 = grouped_nlnso.apply(lambda x: x.Metric.mean(), include_groups=False)\n",
    "df1 = df1.reset_index().rename(columns={0: \"Metric\"})\n",
    "\n",
    "df3 = grouped_nlnso.apply(lambda x: x.MetricVal.mean(), include_groups=False)\n",
    "df3 = df3.reset_index().rename(columns={0: \"MetricEstimate\"})\n",
    "df1.loc[:,\"MetricEstimate\"] = df3.loc[:,\"MetricEstimate\"]\n",
    "df1[\"MetricDiff\"] = df1[\"MetricEstimate\"]- df1[\"Metric\"]\n",
    "\n",
    "df4 = grouped_nlnso.apply(lambda x: x.Inner[x.MetricVal.idxmax()], include_groups=False)\n",
    "df4 = df4.reset_index().rename(columns={0: \"Inner\"})\n",
    "df1.loc[:,\"Repetition\"] = 1\n",
    "df1.loc[:,\"Inner\"] = df4.loc[:,\"Inner\"]\n",
    "\n",
    "\n",
    "df2 = grouped_nnlnso.apply(lambda x: x.Metric.mean(), include_groups=False)\n",
    "df2 = df2.reset_index().rename(columns={0: \"Metric\"})\n",
    "\n",
    "df3 = grouped_nnlnso.apply(lambda x: x.Outer[x.MetricValTest.idxmax()], include_groups=False)\n",
    "df3 = df3.reset_index().rename(columns={0: \"Outer\"})\n",
    "df2.loc[:,'Outer'] = df3.loc[:,\"Outer\"]\n",
    "\n",
    "df4 = grouped_nnlnso.apply(lambda x: x.Inner[x.MetricValTest.idxmax()], include_groups=False)\n",
    "df4 = df4.reset_index().rename(columns={0: \"Inner\"})\n",
    "df2.loc[:,\"Inner\"] = df4.loc[:,\"Inner\"]\n",
    "\n",
    "df4 = grouped_nnlnso.apply(lambda x: x.MetricTest.mean(), include_groups=False)\n",
    "df4 = df4.reset_index().rename(columns={0: \"MetricEstimate\"})\n",
    "df2.loc[:,\"MetricEstimate\"] = df4.loc[:,\"MetricEstimate\"]\n",
    "df2[\"MetricDiff\"] = df2[\"MetricEstimate\"]- df2[\"Metric\"]\n",
    "\n",
    "df2 = pd.concat([df1, df2])\n",
    "del df3, df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b658f176-18da-48c7-bd49-5737e0ab1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model:\n",
    "    for k in task:\n",
    "        diff_nlnso = df2.loc[(df2[\"Model\"]==i) & (df2[\"Task\"]==k) & (df2[\"Partition\"]==\"NLNSO\"), \"MetricDiff\"].values\n",
    "        diff_nnlnso = df2.loc[(df2[\"Model\"]==i) & (df2[\"Task\"]==k) & (df2[\"Partition\"]==\"NNLNSO\"), \"MetricDiff\"].values\n",
    "        print(\n",
    "            f'{get_full_name(i):15} - {get_full_name(k):10}:',\n",
    "            f'{np.abs(diff_nlnso).mean():10.4f} / ',\n",
    "            f'{np.abs(diff_nnlnso).mean():10.4f} / ',\n",
    "            f'{np.median(np.abs(diff_nlnso)):10.4f} / ',\n",
    "            f'{np.median(np.abs(diff_nnlnso)):10.4f} ',\n",
    "        )\n",
    "\n",
    "print('\\n\\n')\n",
    "for i in model:\n",
    "    for k in task:\n",
    "        diff_nlnso = df2.loc[(df2[\"Model\"]==i) & (df2[\"Task\"]==k) & (df2[\"Partition\"]==\"NLNSO\"), \"MetricDiff\"].values\n",
    "        diff_nnlnso = df2.loc[(df2[\"Model\"]==i) & (df2[\"Task\"]==k) & (df2[\"Partition\"]==\"NNLNSO\"), \"MetricDiff\"].values\n",
    "        print(\n",
    "            f'{get_full_name(i):15} - {get_full_name(k):10}:',\n",
    "            f'{np.abs(diff_nlnso).std():10.4f} / ',\n",
    "            f'{np.abs(diff_nnlnso).std():10.4f} / ',\n",
    "            f'{np.subtract(*np.percentile(np.abs((diff_nlnso)),[75, 25])):10.4f} / ',\n",
    "            f'{np.subtract(*np.percentile(np.abs((diff_nnlnso)),[75, 25])):10.4f} ',\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ed5dc-5a42-4ac3-84b1-7e593d62ec3c",
   "metadata": {},
   "source": [
    "## LOSO vs Full N-LOSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be54adb-02df-448a-ac10-a4b48af67ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsubj_dict = {'alz': 88, 'pds': 81,'bci': 106}\n",
    "\n",
    "metric = 'accuracy_weighted'\n",
    "task = ['pds', 'alz', 'bci']\n",
    "model = ['shn', 'egn', 'dcn', 'res']\n",
    "partition = ['LOSO', 'NLOSO']\n",
    "\n",
    "performances, performancesval = gather_metric_values(metric, task, model, partition, True)\n",
    "performances_df = convert_performance_totable(performances)\n",
    "performancesval_df = convert_performance_totable(performancesval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701f08e-da35-4982-bb9c-8079661ecea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsubj_dict = {'alz': 88,'pds': 81,'bci': 106}\n",
    "for k in task:\n",
    "    Nsubj = Nsubj_dict[k]\n",
    "    for i in ['egn']:\n",
    "        loso = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"LOSO\")\n",
    "        ), \"Metric\"].values\n",
    "        nloso_pd = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"NLOSO\")\n",
    "        )]\n",
    "        nloso = nloso_pd[\"Metric\"].values\n",
    "        nloso = nloso.reshape(Nsubj,Nsubj-1)\n",
    "        nloso_med = np.median(nloso,1)\n",
    "        nloso_min = np.min(nloso,1)\n",
    "        nloso_max = np.max(nloso,1)\n",
    "        nloso_err = np.stack((nloso_med-nloso_min, nloso_max-nloso_med),1).T\n",
    "\n",
    "        amd = loso\n",
    "        bmd = nloso_med\n",
    "        #print(i, k, (((bmd-amd)>0).sum()) )\n",
    "\n",
    "        amd = np.median(nloso_max)\n",
    "        bmd = np.percentile(nloso_max, 75) - np.percentile(nloso_max, 25)\n",
    "        #print(i, k, f'{amd:.3f}, {bmd:.3f}' )\n",
    "        \n",
    "        amd = np.median(loso)\n",
    "        bmd = np.median(nloso.reshape(-1))\n",
    "        cmd = 100*(amd-bmd)/amd\n",
    "        #print(i, k, f'{amd:.3f}, {bmd:.3f}, {cmd:.3f}' )\n",
    "        \n",
    "        amd = np.percentile(loso, 25)\n",
    "        bmd = np.percentile(nloso.reshape(-1), 25)\n",
    "        cmd = 100*(amd-bmd)/amd\n",
    "        #print(i, k, f'{amd:.3f}, {bmd:.3f}, {cmd:.3f}' )\n",
    "\n",
    "        amd = np.percentile(loso, 75)\n",
    "        bmd = np.percentile(nloso.reshape(-1), 75)\n",
    "        cmd = 100*(amd-bmd)/amd\n",
    "        #print(i, k, f'{amd:.3f}, {bmd:.3f}, {cmd:.3f}' )\n",
    "\n",
    "        amd = np.percentile(loso, 75) - np.percentile(loso, 25)\n",
    "        bmd = np.percentile(nloso.reshape(-1), 75) - np.percentile(nloso.reshape(-1), 25)\n",
    "        cmd = 100*(amd-bmd)/amd\n",
    "        print(i, k, f'{amd:.3f}, {bmd:.3f}, {cmd:.3f}' )\n",
    "\n",
    "        amd = np.mean(loso)\n",
    "        bmd = np.mean(nloso.reshape(-1))\n",
    "        cmd = 100*(amd-bmd)/amd\n",
    "        #print(i, k, f'{amd:.3f}, {bmd:.3f}, {cmd:.3f}' )\n",
    "\n",
    "        amd = np.std(loso)\n",
    "        bmd = np.std(nloso.reshape(-1))\n",
    "        cmd = 100*(amd-bmd)/amd\n",
    "        #print(i, k, f'{amd:.3f}, {bmd:.3f}, {cmd:.3f}' )\n",
    "\n",
    "    #print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714d29c-fe8f-4193-908d-3369320f4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsubj_dict = {'alz': 88,'pds': 81,'bci': 106}\n",
    "boxcolor     = \"#56b4e9\"#'#d55e00'\n",
    "fliercolor   = 'gray'\n",
    "linecolor    = '#137'\n",
    "scattercolor = \"#c97b63\"#009292' \n",
    "\n",
    "scattercolor = \"#0072b2\"#'#009292' \n",
    "boxcolor     = '#e69f00'\n",
    "\n",
    "font = 22\n",
    "for k in task:\n",
    "    Nsubj = Nsubj_dict[k]\n",
    "    for n, i in enumerate(model):\n",
    "        loso = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"LOSO\")\n",
    "        ), \"Metric\"].values\n",
    "        nloso_pd = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"NLOSO\")\n",
    "        )]\n",
    "        nloso = nloso_pd[\"Metric\"].values\n",
    "        nloso = nloso.reshape(Nsubj,Nsubj-1)\n",
    "        range_x = np.arange(Nsubj)\n",
    "        fig, ax = plt.subplots(figsize=(6.574*3, 2.41*3)) #2.95\n",
    "        sns.scatterplot(\n",
    "            x=range_x, y=loso, ax=ax, hue=np.zeros(Nsubj), legend=False,\n",
    "            edgecolor = 'black', zorder=10, palette=[scattercolor])\n",
    "        ax.collections[0].set_sizes([50])\n",
    "        sns.boxplot(\n",
    "            data=nloso_pd,\n",
    "            x=\"Outer\",\n",
    "            y=\"Metric\",\n",
    "            ax=ax,\n",
    "            fill=True,\n",
    "            showfliers=False,\n",
    "            linecolor = linecolor,\n",
    "            flierprops = dict(\n",
    "                marker='o',\n",
    "                markerfacecolor=fliercolor,\n",
    "                linestyle='none',\n",
    "                markeredgecolor=fliercolor\n",
    "            ),\n",
    "            boxprops=dict(alpha=.8),\n",
    "            palette=[boxcolor]*Nsubj,\n",
    "            width = 0.625,\n",
    "            #saturation = .9\n",
    "        ) #56b4e9\n",
    "        ax.set_yticks([i*10 for i in range(0, 11)])\n",
    "        #ax.set_xticks([5-1] + [i*5-1 for i in range(2, (Nsubj)//5 +1)])\n",
    "        \n",
    "        ax.xaxis.set_major_locator(MultipleLocator(5, offset=-1))\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "        \n",
    "        ax.tick_params(axis='both', which='major', labelsize=font-3)\n",
    "        ax.set_title(\n",
    "            f'Model: {get_full_name(i)} - Task: {get_full_name(k)}',\n",
    "            fontsize = font+3,\n",
    "            pad = 16\n",
    "        )\n",
    "        ax.set_xlabel('Subject ID', fontsize = font)\n",
    "        ax.set_ylabel('Balanced Accuracy %', fontsize = font)\n",
    "        if k == 'bci':\n",
    "            ax.set_ylim(16, 94)\n",
    "        else:\n",
    "            ax.set_ylim(-3,102)\n",
    "        ax.xaxis.grid(True, linewidth=1.5)\n",
    "        ax.yaxis.grid(True, linewidth=1.5)\n",
    "        ax.grid(which='minor', alpha=0.3)\n",
    "        ax.grid(which='major', alpha=0.8)\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(1.5)\n",
    "\n",
    "        if k == 'bci':\n",
    "            ax.text(0, 98.5, f'$({letters[n]})$',fontsize = font+3)\n",
    "        else:\n",
    "            ax.text(0, 106.5, f'$({letters[n]})$',fontsize = font+3)\n",
    "        file_name = f\"Images/{folder}/LOSO_vs_FNLOSO_model_{get_full_name(i)}_tasks_{get_full_name(k)}.pdf\"\n",
    "        plt.savefig(file_name, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f6c07-e1ce-4860-82c8-5959c45b75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsubj_dict = {'alz': 88,'pds': 81,'bci': 106}\n",
    "boxcolor     = \"#56b4e9\"#'#d55e00'\n",
    "fliercolor   = 'gray'\n",
    "linecolor    = '#137'\n",
    "scattercolor = \"#c97b63\"#009292' \n",
    "\n",
    "scattercolor = \"#0072b2\"#'#009292' \n",
    "boxcolor     = '#e69f00'\n",
    "\n",
    "font = 21\n",
    "for k in task:\n",
    "    Nsubj = Nsubj_dict[k]\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(6.574*3, 7.6457*3)) #2.95\n",
    "    for n, i in enumerate(model):\n",
    "        row, col = n, 1\n",
    "        loso = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"LOSO\")\n",
    "        ), \"Metric\"].values\n",
    "        nloso_pd = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"NLOSO\")\n",
    "        )]\n",
    "        nloso = nloso_pd[\"Metric\"].values\n",
    "        nloso = nloso.reshape(Nsubj,Nsubj-1)\n",
    "        range_x = np.arange(Nsubj)\n",
    "        sns.scatterplot(\n",
    "            x=range_x, y=loso, ax=ax[row], hue=np.zeros(Nsubj), legend=False,\n",
    "            edgecolor = 'black', zorder=10, palette=[scattercolor])\n",
    "        ax[row].collections[0].set_sizes([50])\n",
    "        sns.boxplot(\n",
    "            data=nloso_pd,\n",
    "            x=\"Outer\",\n",
    "            y=\"Metric\",\n",
    "            ax=ax[row],\n",
    "            fill=True,\n",
    "            showfliers=False,\n",
    "            linecolor = linecolor,\n",
    "            flierprops = dict(\n",
    "                marker='o',\n",
    "                markerfacecolor=fliercolor,\n",
    "                linestyle='none',\n",
    "                markeredgecolor=fliercolor\n",
    "            ),\n",
    "            boxprops=dict(alpha=.8),\n",
    "            palette=[boxcolor]*Nsubj,\n",
    "            width = 0.625,\n",
    "            #saturation = .9\n",
    "        ) #56b4e9\n",
    "        ax[row].set_yticks([i*10 for i in range(0, 11)])\n",
    "        #ax.set_xticks([5-1] + [i*5-1 for i in range(2, (Nsubj)//5 +1)])\n",
    "        ax[row].xaxis.set_major_locator(MultipleLocator(5, offset=-1))\n",
    "        ax[row].xaxis.set_minor_locator(MultipleLocator(1))\n",
    "        ax[row].tick_params(axis='both', which='major', labelsize=font-3)\n",
    "\n",
    "        # Specify the minor ticks where you want labels\n",
    "        #minor_ticks = [1] + [None]*(Nsubj_dict[k]-2) +[88]\n",
    "        #ax[row].set_xticks([i for i in range(Nsubj_dict[k])], minor=True)\n",
    "        #ax[row].set_xticklabels(minor_ticks, minor=True)\n",
    "        #ax[row].tick_params(axis='both', which='minor', labelsize=font-3, pad=4.5)\n",
    " \n",
    "        ax[row].set_title(\n",
    "            f'Model: {get_full_name(i)} - Task: {get_full_name(k)}',\n",
    "            fontsize = font+3,\n",
    "            pad = 16\n",
    "        )\n",
    "        ax[row].set_ylabel('Balanced Accuracy %', fontsize = font)\n",
    "        if n==3:\n",
    "            ax[row].set_xlabel('Subject ID', fontsize = font)\n",
    "        else:\n",
    "            ax[row].xaxis.label.set_visible(False)\n",
    "        \n",
    "        if k == 'bci':\n",
    "            ax[row].set_ylim(16, 94)\n",
    "        else:\n",
    "            ax[row].set_ylim(-3,102)\n",
    "        \n",
    "        ax[row].xaxis.grid(True, linewidth=1.5)\n",
    "        ax[row].yaxis.grid(True, linewidth=1.5)\n",
    "        ax[row].grid(which='minor', alpha=0.3)\n",
    "        ax[row].grid(which='major', alpha=0.8)\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax[row].spines[axis].set_linewidth(1.5)\n",
    "\n",
    "        if k == 'bci':\n",
    "            ax[row].text(0, 98.5, f'$({letters[n]})$',fontsize = font+3)\n",
    "        else:\n",
    "            ax[row].text(0, 106.5, f'$({letters[n]})$',fontsize = font+3)\n",
    "\n",
    "    fig_title = f'Leave-One-Subject-Out (blue dots) vs. Nested-Leave-One-Subjects-Out (orange boxes)'\n",
    "    fig.suptitle(fig_title, fontsize= font+5.5)\n",
    "    plt.subplots_adjust(top=.935, hspace=0.28)\n",
    "    file_name = f\"Images/{folder}/LOSO_vs_FNLOSO_all_models_tasks_{get_full_name(k)}.pdf\"\n",
    "    plt.savefig(file_name, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58bff35-d60a-460e-b131-1fa6dcdc62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsubj_dict = {'pds': 81, 'alz': 88, 'bci': 106}\n",
    "font=25\n",
    "metric_diff = [np.zeros((4, Nsubj)) for Nsubj in Nsubj_dict.values()]\n",
    "metric_var = [np.zeros((4, Nsubj)) for Nsubj in Nsubj_dict.values()]\n",
    "\n",
    "\n",
    "for n, k in enumerate(task):\n",
    "    Nsubj = Nsubj_dict[k]\n",
    "    for m, i in enumerate(model):\n",
    "        loso = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"LOSO\")\n",
    "        ), \"Metric\"].values\n",
    "        nloso_pd = performances_df.loc[(\n",
    "            (performances_df['Task']==k) &\n",
    "            (performances_df['Model']==i) & \n",
    "            (performances_df['Partition']==\"NLOSO\")\n",
    "        )]\n",
    "        nloso = nloso_pd[\"Metric\"].values\n",
    "        nloso = nloso.reshape(Nsubj,Nsubj-1)\n",
    "        nloso_med = np.median(nloso,1)\n",
    "        nloso_var = np.subtract(*np.percentile(nloso,[75, 25], axis=1))\n",
    "        metric_diff[n][m] = loso - nloso_med\n",
    "        metric_var[n][m] = nloso_var\n",
    "    \n",
    "    nloso = pd.DataFrame(metric_diff[n].T, columns=[get_full_name(l) for l in model])\n",
    "    nloso['Task'] = get_full_name(k)\n",
    "    nloso_var = pd.DataFrame(metric_var[n].T, columns=[get_full_name(l) for l in model])\n",
    "    nloso_var['Task'] = get_full_name(k)\n",
    "    if n==0:\n",
    "        nloso_tot = nloso\n",
    "        nloso_var_tot = nloso_var\n",
    "    else:\n",
    "        nloso_tot = pd.concat([nloso_tot, nloso])\n",
    "        nloso_var_tot = pd.concat([nloso_var_tot, nloso_var])\n",
    "\n",
    "nloso_tot = pd.melt(\n",
    "    nloso_tot,\n",
    "    id_vars=['Task'],\n",
    "    value_vars=['ShallowConvNet', 'EEGNet',  'DeepConvNet', 'T-ResNet'],\n",
    "    var_name='Model',\n",
    "    value_name='Metric'\n",
    ")\n",
    "\n",
    "nloso_var_tot = pd.melt(\n",
    "    nloso_var_tot,\n",
    "    id_vars=['Task'],\n",
    "    value_vars=['ShallowConvNet', 'EEGNet', 'DeepConvNet', 'T-ResNet'],\n",
    "    var_name='Model',\n",
    "    value_name='Metric'\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(19.72, 8.8))\n",
    "sns.boxplot(\n",
    "    data      = nloso_tot,\n",
    "    x         = 'Task',\n",
    "    y         = 'Metric',\n",
    "    legend    = True,\n",
    "    linewidth = 1.5,\n",
    "    hue       = 'Model',\n",
    "    ax        = ax[0],\n",
    "    showfliers= False,\n",
    "    boxprops=dict(alpha=.9),\n",
    "    linecolor = '#137',\n",
    "    palette   = [\"#f0e442\", \"#0072b2\", \"#e69f00\", \"#009e73\"]\n",
    ")\n",
    "ax[0].legend(fontsize = font-7, loc = \"upper right\")\n",
    "ax[0].yaxis.set_major_locator(MultipleLocator(10))\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=font-5)\n",
    "ax[0].set_xlabel('Task', fontsize = font-2)\n",
    "#ax[0].set_ylabel(r'Subject-wise $\\Delta_{\\text{N-LOSO}}$', fontsize = font)\n",
    "ax[0].set_ylabel(r'Subject-wise [$\\text{LOSO}_{\\text{Acc}}-\\text{med(N-LOSO}_{\\text{Acc}})$]', fontsize = font-2)\n",
    "ax[0].set_title(f'Accuracy difference between\\nLOSO and median N-LOSO.\\nDistribution across subjects', fontsize = font)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax[0].spines[axis].set_linewidth(1.5)\n",
    "ax[0].text(-0.8, 96.5, f'$(A)$',fontsize = font+3)\n",
    "\n",
    "sns.boxplot(\n",
    "    data      = nloso_var_tot,\n",
    "    x         = 'Task',\n",
    "    y         = 'Metric',\n",
    "    legend    = True,\n",
    "    linewidth = 1.5,\n",
    "    hue       = 'Model',\n",
    "    ax        = ax[1],\n",
    "    showfliers= False,\n",
    "    linecolor = '#137',\n",
    "    palette   = [\"#f0e442\", \"#0072b2\", \"#e69f00\", \"#009e73\"]\n",
    ")\n",
    "ax[1].legend(fontsize = font-7, loc = \"upper right\")\n",
    "ax[1].yaxis.set_major_locator(MultipleLocator(10))\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=font-5)\n",
    "ax[1].set_xlabel('Task', fontsize = font-2)\n",
    "ax[1].set_ylabel(r'Subject-wise $\\text{IQR}_{\\text{N-LOSO}}$', fontsize = font-2)\n",
    "ax[1].set_title(f'N-LOSO interquartile range (IQR).\\nDistribution across subjects', fontsize = font)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax[1].spines[axis].set_linewidth(1.5)\n",
    "ax[1].text(-0.8, 106.5, f'$(B)$',fontsize = font+3)\n",
    "plt.savefig(f\"Images/{folder}/LOSO_vs_FNLOSO_model_delta_and_iqr.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673578c-0824-47ed-bf69-67ef120bca01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
